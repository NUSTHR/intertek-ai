module_id: 9 #"09_compliance_conclusions"
title: "Final Compliance Determination"
description: "Maps parameter states to final legal conclusions and comprehensive obligation views based on Regulation (EU) 2024/1689."

# ==============================================================================
# VARIABLES SECTION
# Determines Type, Risk_level, and View dynamically based on logic.
# ==============================================================================

variables:
  - name: "Type"
    type: "string"
    initial_value: "Undetermined"
    rules:
      - condition: "AI_type == 3"
        value: "Non-regulated products"
      - condition: "AI_type == 1"
        value: "General-Purpose AI Model"
      - condition: "AI_type == 2"
        value: "AI System"
      - condition: "else"
        value: "Undetermined"

  - name: "Risk_level"
    type: "string"
    initial_value: "Undetermined"
    rules:
      # Group 1: Hard Stops
      - condition: "Totally_excluded == True"
        value: "Out of Regulation"
      - condition: "System_excluded == True"
        value: "Out of Regulation"
      - condition: "Unacceptable_risk == True"
        value: "Unacceptable Risk (Prohibited practices)"
      - condition: "AI_type == 3"
        value: "Out of Regulation"
      
      # Group 2: Real World Testing (RWT) overrides
      - condition: "Real_world_Testing == True and AI_type == 2 and High_risk == True and Transparency_obligation == True"
        value: "High Risk with Additional Transparency Obligation (Real World Testing)"
      - condition: "Real_world_Testing == True and AI_type == 2 and High_risk == True and Transparency_obligation == False"
        value: "High Risk (Real World Testing)"
      - condition: "Real_world_Testing == True and AI_type == 2 and High_risk == False and Transparency_obligation == True"
        value: "Transparency Obligation Only"
      - condition: "Real_world_Testing == True and AI_type == 2 and High_risk == False and Transparency_obligation == False and Open_source == True"
        value: "Minimal Risk (Open Source)"      
      - condition: "Real_world_Testing == True and AI_type == 2 and High_risk == False and Transparency_obligation == False and Open_source == False"
        value: "Minimal Risk"
      # Group 3: GPAI Market Placement
      - condition: "AI_type == 1 and Systematic_risk == True"
        value: "Systemic Risk GPAI"
      - condition: "AI_type == 1 and Systematic_risk == False and Open_source == False"
        value: "Standard GPAI"
      - condition: "AI_type == 1 and Systematic_risk == False and Open_source == True"
        value: "Standard GPAI (Open Source Exempt)"

      # Group 4: AI Systems Market Placement
      - condition: "AI_type == 2 and High_risk == True and Transparency_obligation == True"
        value: "High Risk with Additional Transparency Obligations"
      - condition: "AI_type == 2 and High_risk == True and Transparency_obligation == False"
        value: "High Risk"
      - condition: "AI_type == 2 and High_risk == False and Transparency_obligation == True"
        value: "Transparency Obligation Only"
      - condition: "AI_type == 2 and High_risk == False and Transparency_obligation == False and Open_source == True"
        value: "Minimal Risk (Open Source)"
      - condition: "AI_type == 2 and High_risk == False and Transparency_obligation == False and Open_source == False"
        value: "Minimal Risk"
      - condition: "Role == 'Undetermined'"
        value: "No Regulated Role Identified"
      # Fallback
      - condition: "else"
        value: "Undetermined"

  - name: "Risk_Level_Reason"
    type: "string"
    initial_value: "Reason undetermined."
    rules:
      # Group 1: Hard Stops (Extracts from Modules 1, 3, 4)
      - condition: "Totally_excluded == True"
        value: "This activity is excluded from the scope of the AI Act. Reason: {{Exclusion_reason}}" 
      - condition: "System_excluded == True"
        value: "This system is specifically exempt from the Regulation. Reason: {{Exclusion_Reason}}" 
      - condition: "Unacceptable_risk == True"
        value: "This AI practice is classified as 'Unacceptable Risk' and is strictly prohibited. Reason: {{Prohibited_reason}}" 
      - condition: "AI_type == 3"
        value: "This software falls outside the scope of the Regulation because it does not meet the legal definition of an 'AI System' or a 'General-Purpose AI Model' under Article 3."

      # Group 2: Real World Testing (RWT) overrides
      - condition: "Real_world_Testing == True and AI_type == 2 and High_risk == True"
        value: "You are conducting real-world testing on a High-Risk AI System. This high-risk status applies because {{High_risk_reason}}. Therefore, the testing is subject to the governance requirements of Article 60."
      - condition: "Real_world_Testing == True and AI_type == 2 and High_risk == False and Transparency_obligation == True"
        value: "You are conducting real-world testing on a system that interacts with persons or generates content. This triggers transparency obligations because {{Transparency_Reasons}}. You must comply with Article 50 even during testing."
      # Group 3: GPAI Market Placement (Extracts from Module 7)
      - condition: "AI_type == 1 and Systematic_risk == True"
        value: "This model is classified as a General-Purpose AI Model with Systemic Risk. Reason: {{Systematic_reason}}" 
      - condition: "AI_type == 1 and Systematic_risk == False"
        value: "This model is classified as a Standard General-Purpose AI Model. It does not meet the threshold for systemic risk because {{Systematic_reason}}."

      # Group 4: AI Systems Market Placement (Extracts from Module 5 & 6)
      - condition: "AI_type == 2 and High_risk == True and Transparency_obligation == True"
        value: "This system is classified as High-Risk because {{High_risk_reason}}. Additionally, it is subject to transparency obligations because {{Transparency_Reasons}}."
      - condition: "AI_type == 2 and High_risk == True and Transparency_obligation == False"
        value: "This system is classified as High-Risk. Reason: {{High_risk_reason}}"
      - condition: "AI_type == 2 and High_risk == False and Transparency_obligation == True"
        value: "This system is classified as Limited Risk and is subject to transparency obligations. Reason: {{Transparency_Reasons}}"
      - condition: "AI_type == 2 and High_risk == False and Transparency_obligation == False and Open_source == False"
        value: "This system is classified as Minimal Risk because it meets none of the conditions for Unacceptable Risk, High-Risk, or Transparency Obligations defined in the Regulation."
      - condition: "AI_type == 2 and High_risk == False and Transparency_obligation == False and Open_source == True"
        value: "This system is classified as Minimal Risk (Open Source). It is released under a free and open-source licence and falls outside the scope of the Regulation, as it does not meet the criteria for Prohibited AI Practices, High-Risk AI Systems, or systems subject to Transparency Obligations."

      # Fallback
      - condition: "else"
        value: "A specific risk classification reason could not be determined from the provided inputs."

  - name: "Role_Description"
    type: "string"
    initial_value: "No regulated role identified based on current inputs."
    rules:
      - condition: "Role == 'provider'"
        value: "Per Article 3(3), you are the entity that develops an AI system or general-purpose AI model, or has it developed, and places it on the market or puts it into service under your own name or trademark."
      - condition: "Role == 'deployer'"
        value: "Per Article 3(4), you are the entity using an AI system under your authority for professional purposes, excluding personal non-professional activity."
      - condition: "Role == 'importer'"
        value: "Per Article 3(6), you are the entity located within the Union that places on the market an AI system bearing the name or trademark of a natural or legal person established in a third country."
      - condition: "Role == 'distributor'"
        value: "Per Article 3(7), you are the entity in the supply chain, other than the provider or importer, that makes an AI system available on the Union market."
      - condition: "Role == 'authorized_representative'"
        value: "Per Article 3(5), you are the entity located in the Union that has received and accepted a written mandate from a provider to perform specific obligations and procedures on their behalf."
      - condition: "Role == 'product_manufacturer'"
        value: "Per Article 2(1)(e), you are the manufacturer placing an AI system on the market or putting it into service together with your product and under your own name or trademark."
      - condition: "Role == 'Undetermined'"
        value: "The legal role of the entity remains undefined based on the provided inputs, preventing the assignment of specific liability or obligations under AI Act."

  - name: "Product_Type_Description"
    type: "string"
    initial_value: "Product type undetermined."
    rules:
      - condition: "Type == 'AI System'"
        value: "Per Article 3(1), this is a machine-based system designed to operate with varying levels of autonomy that infers from inputs how to generate outputs such as predictions, content, recommendations, or decisions influencing environments."
      - condition: "Type == 'General-Purpose AI Model'"
        value: "Per Article 3(63), this is an AI model that displays significant generality, is capable of competently performing a wide range of distinct tasks, and can be integrated into a variety of downstream systems or applications."
      - condition: "Type == 'Non-regulated products'"
        value: "Based on the user input, the software does not meet the definition of an AI system under Article 3(1) or a general-purpose AI model under Article 3(63) and is therefore outside the scope of the AI Act."

  - name: "View"
    type: "string"
    initial_value: ""
    rules:
      # ------------------------------------------------------------------------
      # PRIORITY 1: HARD EXCLUSIONS (Regulation does not apply)
      # ------------------------------------------------------------------------
      - condition: "Totally_excluded == True"
        value: |
          This activity is classified as falling outside the regulated scope of the AI Act[cite: 52, 55]. The project is exempt from mandatory obligations, provided it remains within specific boundaries such as pure scientific research and development or pre-market research activities[cite: 52, 55].
          For more details, please refer to Article 2(6) (Research Exemption) [cite: 52], Article 2(8) (Pre-market R&D)[cite: 55].

      - condition: "System_excluded == True"
        value: |
          This system qualifies for an exemption under Article 2. This applies if the system is exclusively for military, defence, or national security purposes [cite: 48], or if it is used by public authorities in a third country for international law enforcement cooperation under adequate safeguards[cite: 50]. Note that "dual-use" systems (civilian and military) do not qualify for the military exemption[cite: 48].
          For more details, please refer to Article 2(3) (Military/National Security) [cite: 48], Article 2(4) (Third Country Law Enforcement)[cite: 50].

      - condition: "Type == 'Non-regulated products'"
        value: |
          The software does not meet the legal definition of an 'AI System' [cite: 65] or a 'General-Purpose AI Model'[cite: 141]. Therefore, it falls outside the regulatory scope. You should strictly monitor the software's development to ensure it does not evolve into an AI system (e.g., by adding varying levels of autonomy or inference capabilities)[cite: 65].
          For more details, please refer to Article 3(1) (Definition of AI System) [cite: 65], Article 3(63) (Definition of GPAI Model)[cite: 141].

      # ------------------------------------------------------------------------
      # PRIORITY 2: PROHIBITIONS (Regulation bans the activity)
      # ------------------------------------------------------------------------
      - condition: "Unacceptable_risk == True"
        value: |
          This AI practice is strictly prohibited under Article 5[cite: 152]. Banned practices include manipulative techniques [cite: 154], exploitation of vulnerabilities [cite: 155], social scoring [cite: 156], untargeted facial scraping [cite: 161], and emotion recognition in workplaces/schools[cite: 162]. Placing this system on the market is forbidden for all operators, including providers, deployers, distributors, importers and so forth.
          For more details, please refer to Article 5 (Prohibited Practices)[cite: 152].

      # ------------------------------------------------------------------------
      # PRIORITY 3: ROLE CHECK
      # ------------------------------------------------------------------------
      - condition: "Role == 'Undetermined'"
        value: |
          Your entity does not fit the definition of a regulated economic operator (Provider, Deployer, Importer, Distributor, or Authorized Representative)[cite: 67, 68, 69, 70, 71]. Review Article 25 to ensure you are not a 'Product Manufacturer' placing AI on the market under your name, which would reclassify you as a Provider[cite: 476].
          For more details, please refer to Article 3 (Definitions) [cite: 63], Article 25 (Responsibilities along the AI value chain)[cite: 468].

      # ------------------------------------------------------------------------
      # PRIORITY 3: REAL WORLD TESTING (EXPANDED)
      # ------------------------------------------------------------------------
      - condition: "(Risk_level == 'High Risk with Additional Transparency Obligation (Real World Testing)') and (Role == 'provider')"
        value: |
          As a provider, you must submit a real-world testing plan to the market surveillance authority [cite: 1003], register the testing in the EU database [cite: 1007], and obtain informed consent from subjects[cite: 1016]. You must also ensure the system is detectable as AI to affected persons[cite: 783].
          For more details, please refer to Article 60 (Real World Testing) [cite: 994], Article 61 (Informed Consent) [cite: 1027], Article 50 (Transparency) [cite: 783], Article 71 (Registration)[cite: 1178].

      - condition: "(Risk_level == 'High Risk with Additional Transparency Obligation (Real World Testing)') and (Role != 'provider')"
        value: |
          If you are a deployer, prospective deployer or partner. You must conclude an agreement with the provider specifying roles[cite: 1015]. You must ensure subjects are informed they are interacting with AI[cite: 783]. If you are an Authorised Representative, you may need to facilitate registration[cite: 1007].
          For more details, please refer to Article 60 (Testing Conditions) [cite: 1014], Article 61 (Informed Consent) [cite: 1027], Article 50 (Transparency)[cite: 783].

      - condition: "(Risk_level == 'High Risk (Real World Testing)') and (Role == 'provider')"
        value: |
          As a provider, you must draw up and submit a testing plan to the market surveillance authority[cite: 1003]. You must register the testing in the EU database [cite: 1007] and ensure informed consent is obtained from all subjects[cite: 1016].
          For more details, please refer to Article 60 (Real World Testing) [cite: 994], Article 61 (Informed Consent) [cite: 1027], Article 71 (EU Database)[cite: 1178].

      - condition: "(Risk_level == 'High Risk (Real World Testing)') and (Role != 'provider')"
        value: |
          If you are a deployer, prospective deployer or partner, you must strictly adhere to the agreement concluded with the provider [cite: 1015] and ensure the instructions for use are followed[cite: 1014]. You must maintain oversight to protect subject safety[cite: 1017].
          For more details, please refer to Article 60 (Testing Conditions) [cite: 1014], Article 61 (Informed Consent)[cite: 1027].

      # ------------------------------------------------------------------------
      # PRIORITY 4: GENERAL-PURPOSE AI (GPAI)
      # ------------------------------------------------------------------------
      - condition: "(Risk_level == 'Systemic Risk GPAI' and Open_source == False) and (Role == 'provider')"
        value: |
          As a provider, you must notify the Commission of your systemic risk status [cite: 814], maintain technical documentation [cite: 831], perform adversarial testing (red-teaming) [cite: 868], and ensure cybersecurity[cite: 871].
          For more details, please refer to Article 52 (Notification) [cite: 814], Article 53 (Documentation) [cite: 831], Article 55 (Systemic Risk Obligations)[cite: 865].

      - condition: "(Risk_level == 'Systemic Risk GPAI' and Open_source == False) and (Role != 'provider')"
        value: |
          Authorised Representatives must hold the mandate to verify documentation and cooperate with the AI Office[cite: 854]. Importers and Downstream Providers integrating the model must ensure the provider has met their obligations; if you integrate this model into a high-risk system, you assume provider obligations[cite: 469].
          For more details, please refer to Article 54 (Authorised Reps) [cite: 849], Article 25 (Value Chain)[cite: 469].

      - condition: "(Risk_level == 'Systemic Risk GPAI' and Open_source == True) and (Role == 'provider')"
        value: |
          As a provider, the "Systemic Risk" classification overrides the open-source exemption[cite: 840]. You must evaluate the model, mitigate systemic risks, and report incidents[cite: 867].
          For more details, please refer to Article 53(2) (Exception Limit) [cite: 840], Article 55 (Systemic Risk Obligations)[cite: 865].

      - condition: "(Risk_level == 'Systemic Risk GPAI' and Open_source == True) and (Role != 'provider')"
        value: |
          Authorised Representatives must facilitate compliance for non-EU providers[cite: 862]. Downstream Providers must treat this as a regulated model despite the license, ensuring their own systems integrating it are compliant.
          For more details, please refer to Article 54 (Authorised Reps) [cite: 862], Article 55 (Systemic Risk Obligations)[cite: 865].

      - condition: "(Risk_level == 'Standard GPAI') and (Role == 'provider')"
        value: |
          As a provider, you must maintain technical documentation [cite: 831], make information available to downstream providers [cite: 832], comply with copyright law [cite: 837], and publish a summary of training content[cite: 838].
          For more details, please refer to Article 53 (Obligations for GPAI Providers)[cite: 829].

      - condition: "(Risk_level == 'Standard GPAI') and (Role != 'provider')"
        value: |
          Authorised Representatives must verify the technical documentation is drawn up and keep copies available for the AI Office[cite: 855, 856]. Downstream Providers rely on the provided documentation to ensure their own compliance[cite: 834].
          For more details, please refer to Article 54 (Authorised Reps) [cite: 849], Article 53 (Information for Downstream)[cite: 833].

      - condition: "(Risk_level == 'Standard GPAI (Open Source Exempt)') and (Role == 'provider')"
        value: |
          As a provider, you are exempt from most documentation obligations[cite: 839]. However, you must still put in place a policy to respect copyright law [cite: 837] and publish a summary of the training content[cite: 838].
          For more details, please refer to Article 53(2) (Open Source Exemption) [cite: 839], Article 53(1)(c)-(d) (Copyright & Summary)[cite: 837, 838].

      - condition: "(Risk_level == 'Standard GPAI (Open Source Exempt)') and (Role != 'provider')"
        value: |
          Authorised Representatives are generally not required for open-source non-systemic models[cite: 862]. Downstream Providers should verify copyright compliance policies are in place.
          For more details, please refer to Article 54(4) (Auth Rep Exemption) [cite: 862], Article 53(1)(c) (Copyright)[cite: 837].

      # ------------------------------------------------------------------------
      # PRIORITY 5: HIGH RISK & TRANSPARENCY
      # ------------------------------------------------------------------------
      - condition: "(Risk_level == 'High Risk with Additional Transparency Obligations') and (Role == 'provider')"
        value: |
          As a provider, you must fulfill all High-Risk obligations (Conformity Assessment, QMS)[cite: 367]. Additionally, you must design the system to inform natural persons they are interacting with AI (e.g., emotion recognition)[cite: 783, 788].
          For more details, please refer to Article 16 (Provider Obligations) [cite: 366], Article 50 (Transparency)[cite: 782].

      - condition: "(Risk_level == 'High Risk with Additional Transparency Obligations') and (Role == 'deployer')"
        value: |
          As a Deployer, you must monitor the system and ensure human oversight[cite: 488]. You are directly responsible for informing persons exposed to the system (e.g., emotion recognition subjects) of its operation[cite: 788].
          For more details, please refer to Article 26 (Deployer Obligations) [cite: 486], Article 50(3) (Emotion Recognition Disclosure)[cite: 788].

      - condition: "(Risk_level == 'High Risk with Additional Transparency Obligations') and ((Role != 'provider') and (Role != 'deployer'))"
        value: |
          Importers and Distributors must verify the system bears the required markings and instructions before making it available[cite: 447, 459]. Authorised Representatives must verify the declaration of conformity[cite: 434]. Product Manufacturers placing the AI under their name assume provider obligations[cite: 476].
          For more details, please refer to Article 23 (Importers) [cite: 443], Article 24 (Distributors) [cite: 458], Article 22 (Authorised Reps) [cite: 428], Article 25 (Manufacturers)[cite: 476].

      - condition: "(Risk_level == 'High Risk') and (Role == 'provider')"
        value: |
          As a provider, you must establish a Risk Management System [cite: 246], ensure Data Governance [cite: 271], draw up Technical Documentation [cite: 296], and undergo Conformity Assessment[cite: 373].
          For more details, please refer to Article 9 (Risk Management) [cite: 245], Article 16 (Provider Obligations) [cite: 366], Article 43 (Conformity)[cite: 690].

      - condition: "(Risk_level == 'High Risk') and (Role == 'deployer')"
        value: |
          As a Deployer, you must use the system according to instructions [cite: 487], assign human oversight [cite: 488], and in some cases conduct a Fundamental Rights Impact Assessment[cite: 518].
          For more details, please refer to Article 26 (Deployer Obligations) [cite: 486], Article 27 (FRIA)[cite: 517].

      - condition: "(Risk_level == 'High Risk') and ((Role != 'provider') and (Role != 'deployer'))"
        value: |
          Importers must ensure the provider has completed conformity assessment and appointed a representative[cite: 445, 448]. Distributors must verify CE markings and documentation[cite: 459]. Authorised Representatives act as the EU contact point and hold documentation[cite: 435]. Product Manufacturers incorporating the AI become providers if they market it under their name[cite: 476].
          For more details, please refer to Article 23 (Importers) [cite: 443], Article 24 (Distributors) [cite: 458], Article 22 (Authorised Reps) [cite: 428], Article 25 (Manufacturers)[cite: 476].

      - condition: "(Risk_level == 'Transparency Obligation Only') and (Role == 'provider')"
        value: |
          As a provider, you must design the system so outputs are machine-readable and marked as artificially generated (e.g., deep fakes)[cite: 785]. You must ensure the system allows deployers to fulfill their disclosure obligations.
          For more details, please refer to Article 50 (Transparency Obligations)[cite: 782].

      - condition: "(Risk_level == 'Transparency Obligation Only') and (Role == 'deployer')"
        value: |
          As a Deployer of a chatbot, deep fake, or emotion recognition system, you are responsible for disclosing the AI nature of the content or interaction to the affected natural persons[cite: 788, 790].
          For more details, please refer to Article 50 (Transparency Obligations)[cite: 782].

      - condition: "(Risk_level == 'Transparency Obligation Only') and (Role != 'provider' and Role != 'deployer')"
        value: |
          Distributors and Importers must verify the system bears the necessary markings or documentation to fulfill Article 50 before making it available. Product Manufacturers integrating such tools must ensure the final product retains these transparency capabilities.
          For more details, please refer to Article 50 (Transparency) [cite: 782], Article 23-24 (General verification duties)[cite: 443, 458].

      # ------------------------------------------------------------------------
      # PRIORITY 6: MINIMAL RISK
      # ------------------------------------------------------------------------
      - condition: "Risk_level == 'Minimal Risk'"
        value: |
          This system falls into the Minimal Risk category. The AI Act imposes no mandatory obligations. However, Providers and Deployers are encouraged to voluntarily adhere to Codes of Conduct[cite: 1446].
          For more details, please refer to Article 95 (Codes of Conduct)[cite: 1446].
      
      - condition: "Risk_level == 'Minimal Risk (Open Source)'"
        value: |
          This system falls into the Minimal Risk category and is released under a free and open-source licence.
          Pursuant to Article 2(12), the Regulation does not apply to AI systems released under free and open-source licences unless they are high-risk, prohibited, or subject to transparency obligations[cite: 61]. Therefore, this system is explicitly exempt from the Regulation's mandatory obligations.
          However, adherence to voluntary Codes of Conduct is still encouraged[cite: 1446].
          For more details, please refer to Article 2 (Scope) and Article 95 (Codes of Conduct)[cite: 1446].

router:
  - condition: "True"
    action: "terminate"
    message: "Generate the report"

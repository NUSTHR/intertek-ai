module_id: 9 #"09_compliance_conclusions"
title: "最终合规判定"
description: "根据人工智能法案第 2024/1689 号条例（欧盟），将参数状态映射到最终法律结论和综合义务视图。"

# ==============================================================================
# VARIABLES SECTION
# Determines Type， Risk_level， and View dynamically based on logic.
# ==============================================================================

variables:
  - name: "Type"
    type: "string"
    initial_value: "Undetermined"
    rules:
      - condition: "AI_type == 3"
        value: "Non-regulated products"
      - condition: "AI_type == 1"
        value: "General-Purpose AI Model"
      - condition: "AI_type == 2"
        value: "AI System"
      - condition: "AI_type == 0"
        value: "Undetermined"
      - condition: "else"
        value: "Undetermined"

  - name: "Risk_level"
    type: "string"
    initial_value: "Undetermined"
    rules:
      # Group 1: Hard Stops
      - condition: "Totally_excluded == True"
        value: "Out of Regulation"
      - condition: "System_excluded == True"
        value: "Out of Regulation"
      - condition: "Unacceptable_risk == True"
        value: "Unacceptable Risk (Prohibited practices)"
      - condition: "AI_type == 3"
        value: "Out of Regulation"
      
      # Group 2: Real World Testing (RWT) overrides
      - condition: "Real_world_Testing == True and AI_type == 2 and High_risk == True and Transparency_obligation == True"
        value: "High Risk with Additional Transparency Obligation (Real World Testing)"
      - condition: "Real_world_Testing == True and AI_type == 2 and High_risk == True and Transparency_obligation == False"
        value: "High Risk (Real World Testing)"
      - condition: "Real_world_Testing == True and AI_type == 2 and High_risk == False and Transparency_obligation == True"
        value: "Transparency Obligation Only"
      - condition: "Real_world_Testing == True and AI_type == 2 and High_risk == False and Transparency_obligation == False and Open_source == True"
        value: "Minimal Risk (Open Source)"      
      - condition: "Real_world_Testing == True and AI_type == 2 and High_risk == False and Transparency_obligation == False and Open_source == False"
        value: "Minimal Risk"
      # Group 3: GPAI Market Placement
      - condition: "AI_type == 1 and Systemic_risk == True"
        value: "Systemic Risk GPAI"
      - condition: "AI_type == 1 and Systemic_risk == False and Open_source == False"
        value: "Standard GPAI"
      - condition: "AI_type == 1 and Systemic_risk == False and Open_source == True"
        value: "Standard GPAI (Open Source)"

      # Group 4: AI Systems Market Placement
      - condition: "AI_type == 2 and High_risk == True and Transparency_obligation == True"
        value: "High Risk with Additional Transparency Obligations"
      - condition: "AI_type == 2 and High_risk == True and Transparency_obligation == False"
        value: "High Risk"
      - condition: "AI_type == 2 and High_risk == False and Transparency_obligation == True"
        value: "Transparency Obligation Only"
      - condition: "AI_type == 2 and High_risk == False and Transparency_obligation == False and Open_source == True"
        value: "Minimal Risk (Open Source)"
      - condition: "AI_type == 2 and High_risk == False and Transparency_obligation == False and Open_source == False"
        value: "Minimal Risk"
      - condition: "Role == 'Undetermined'"
        value: "No Regulated Role Identified"
      # Fallback
      - condition: "else"
        value: "Undetermined"

  # ==============================================================================
  # NEW TRANSLATION VARIABLES (Added per request)
  # ==============================================================================

  - name: "Role_CN"
    type: "string"
    initial_value: "未确定"
    rules:
      - condition: "Role == 'provider'"
        value: "提供者"
      - condition: "Role == 'deployer'"
        value: "部署者"
      - condition: "Role == 'importer'"
        value: "进口商"
      - condition: "Role == 'distributor'"
        value: "分销商"
      - condition: "Role == 'authorized_representative'"
        value: "授权代表"
      - condition: "Role == 'product_manufacturer'"
        value: "产品制造商"
      - condition: "Role == 'Undetermined'"
        value: "未确定"
      - condition: "else"
        value: "未确定"

  - name: "Type_CN"
    type: "string"
    initial_value: "未确定"
    rules:
      - condition: "Type == 'Non-regulated products'"
        value: "非受监管产品"
      - condition: "Type == 'General-Purpose AI Model'"
        value: "通用人工智能模型"
      - condition: "Type == 'AI System'"
        value: "人工智能系统"
      - condition: "else"
        value: "未确定"

  - name: "Risk_level_CN"
    type: "string"
    initial_value: "未确定"
    rules:
      - condition: "Risk_level == 'Out of Regulation'"
        value: "不受监管"
      - condition: "Risk_level == 'Unacceptable Risk (Prohibited practices)'"
        value: "不可接受风险（被禁止的做法）"
      - condition: "Risk_level == 'High Risk with Additional Transparency Obligation (Real World Testing)'"
        value: "具有额外透明度义务的高风险（真实世界测试）"
      - condition: "Risk_level == 'High Risk (Real World Testing)'"
        value: "高风险（真实世界测试）"
      - condition: "Risk_level == 'Transparency Obligation Only'"
        value: "仅透明度义务"
      - condition: "Risk_level == 'Minimal Risk'"
        value: "最小风险"
      - condition: "Risk_level == 'Minimal Risk (Open Source)'"
        value: "最小风险（开源）"
      - condition: "Risk_level == 'Systemic Risk GPAI'"
        value: "具有系统风险的通用人工智能模型"
      - condition: "Risk_level == 'Standard GPAI'"
        value: "标准通用人工智能模型"
      - condition: "Risk_level == 'Standard GPAI (Open Source)'"
        value: "标准通用人工智能模型（开源）"
      - condition: "Risk_level == 'High Risk with Additional Transparency Obligations'"
        value: "具有额外透明度义务的高风险"
      - condition: "Risk_level == 'High Risk'"
        value: "高风险"
      - condition: "Risk_level == 'Transparency Obligation Only'"
        value: "仅透明度义务"
      - condition: "Risk_level == 'No Regulated Role Identified'"
        value: "未识别出受监管角色"
      - condition: "else"
        value: "未确定"

  # ==============================================================================
  # EXISTING OUTPUT VARIABLES
  # ==============================================================================

  - name: "Risk_Level_Reason"
    type: "string"
    initial_value: "Reason undetermined."
    rules:
      # 第 1 组：硬性排除（提取自模块 1、3、4）
      - condition: "Totally_excluded == True"
        value: "此活动不属于《人工智能法案》的适用范围。原因：{{Exclusion_reason}}" 
      - condition: "System_excluded == True"
        value: "该系统属于法规明确豁免的对象。原因：{{Exclusion_Reason}}" 
      - condition: "Unacceptable_risk == True"
        value: "此人工智能实践被归类为“不可接受风险”，受到严格禁止。原因：{{Prohibited_reason}}" 
      - condition: "AI_type == 3"
        value: "该软件不在此法规管辖范围内，因为它不符合第 3 条中关于“人工智能系统”或“通用人工智能模型”的法律定义。"

      # 第 2 组：真实世界测试（RWT）覆盖规则
      - condition: "Real_world_Testing == True and AI_type == 2 and High_risk == True"
        value: "您正在对高风险人工智能系统进行真实世界测试。该高风险状态适用的原因是：{{High_risk_reason}}因此，该测试受第 60 条治理要求的管辖。"
      - condition: "Real_world_Testing == True and AI_type == 2 and High_risk == False and Transparency_obligation == True"
        value: "您正在对涉及人机交互或内容生成的系统进行真实世界测试。这触发了透明度义务，原因是：{{Transparency_Reasons}}即使在测试期间，您也必须遵守第 50 条的规定。"
      # 第 3 组：通用人工智能模型（GPAI）市场投放（提取自模块 7）
      - condition: "AI_type == 1 and Systemic_risk == True"
        value: "此模型被归类为具有系统性风险的通用人工智能模型。原因：{{Systemic_reason}}" 
      - condition: "AI_type == 1 and Systemic_risk == False"
        value: "此模型被归类为标准通用人工智能模型。它未达到系统性风险的阈值，因为：{{Systemic_reason}}"

      # 第 4 组：人工智能系统市场投放（提取自模块 5 和 6）
      - condition: "AI_type == 2 and High_risk == True and Transparency_obligation == True"
        value: "此系统被归类为高风险，原因是：{{High_risk_reason}}此外，它还需履行透明度义务，原因是：{{Transparency_Reasons}}"
      - condition: "AI_type == 2 and High_risk == True and Transparency_obligation == False"
        value: "此系统被归类为高风险。原因：{{High_risk_reason}}"
      - condition: "AI_type == 2 and High_risk == False and Transparency_obligation == True"
        value: "此系统被归类为有限风险，并须履行透明度义务。原因：{{Transparency_Reasons}}"
      - condition: "AI_type == 2 and High_risk == False and Transparency_obligation == False and Open_source == False"
        value: "本系统被归类为“最小风险”，因其未触及本法规所定义的不可接受风险、高风险或透明度义务的相关条件。"
      - condition: "AI_type == 2 and High_risk == False and Transparency_obligation == False and Open_source == True"
        value: "本系统被归类为“最小风险（开源）”。因此系统依据免费及开源许可发布，且因未触及“禁止的人工智能实践”、“高风险人工智能系统”或“受透明度义务约束的系统”之认定标准，故不属于本法规的适用范围。"
      # 回退选项
      - condition: "else"
        value: "无法根据提供的输入确定具体的风险分类原因。"

  - name: "Role_Description"
    type: "string"
    initial_value: "No regulated role identified based on current inputs."
    rules:
      - condition: "Role == 'provider'"
        value: "根据人工智能法案第 3(3) 条，您是开发 AI 系统或通用 AI 模型，或让人开发并以您的名义或商标将其投放市场或投入使用的实体。"
      - condition: "Role == 'deployer'"
        value: "根据人工智能法案第 3(4) 条，您是在您的权限下将 AI 系统用于职业目的（不包括个人非职业活动）的实体。"
      - condition: "Role == 'importer'"
        value: "根据人工智能法案第 3(6) 条，您是位于欧盟境内，将冠以第三国设立的自然人或法人名称或商标的 AI 系统投放市场的实体。"
      - condition: "Role == 'distributor'"
        value: "根据人工智能法案第 3(7) 条，您是供应链中除提供者或进口商之外，使 AI 系统在欧盟市场上可获得的实体。"
      - condition: "Role == 'authorized_representative'"
        value: "根据人工智能法案第 3(5) 条，您是位于欧盟境内，已收到并接受提供者的书面授权，代表其履行特定义务和程序的实体。"
      - condition: "Role == 'product_manufacturer'"
        value: "根据人工智能法案第 2(1)(e) 条，您是将 AI 系统与您的产品一起并以您的名义或商标投放市场或投入使用的制造商。"
      - condition: "Role == 'Undetermined'"
        value: "根据提供的输入，实体的法律角色仍未定义，无法确定《人工智能法》下的具体责任或义务。"

  - name: "Product_Type_Description"
    type: "string"
    initial_value: "Product type undetermined."
    rules:
      - condition: "Type == 'AI System'"
        value: "根据人工智能法案第 3(1) 条，这是一个基于机器的系统，设计为以不同程度的自主性运行，从输入中推断如何生成通过预测、内容、推荐或决定的形式影响环境的输出。"
      - condition: "Type == 'General-Purpose AI Model'"
        value: "根据人工智能法案第 3(63) 条，这是一种显示出显著通用性、能够胜任广泛的独特任务，并可以集成到各种下游系统或应用中的 AI 模型。"
      - condition: "Type == 'Non-regulated products'"
        value: "根据用户输入，该软件不符合第 3(1) 条下人工智能系统或第 3(63) 条下通用人工智能模型的定义，因此不属于《人工智能法》的适用范围。"
      - condition: "else"
        value: "根据用户输入，产品的具体类别仍未定义，无法确定《人工智能法》下的具体义务范围"

  - name: "View"
    type: "string"
    initial_value: ""
    rules:
      # ------------------------------------------------------------------------
      # 优先级 1：硬性排除（法规不适用）
      # ------------------------------------------------------------------------
      - condition: "Totally_excluded == True"
        value: |
          此活动被归类为《人工智能法案》监管范围之外。只要项目保持在特定界限内（如纯科学研究和开发或上市前研究活动），则免除强制性义务。
          更多详情，请参阅《人工智能法案》第 2(6) 条（研究豁免）及第 2(8) 条（上市前研发）。

      - condition: "System_excluded == True"
        value: |
          根据《人工智能法案》第 2 条，该系统符合豁免条件。这适用于专用于军事、国防或国家安全目的的系统，或者由第三国公共当局用于国际执法合作且有充分保障措施的情况。注意，“两用”系统（军民两用）不符合军事豁免资格。
          更多详情，请参阅《人工智能法案》第 2(3) 条（军事/国家安全）及第 2(4) 条（第三国执法）。

      - condition: "Type == 'Non-regulated products'"
        value: |
          该软件满足豁免条件，或不符合“人工智能系统”或“通用人工智能模型”的法律定义。因此，它不属于监管范围。您应严格监控软件的开发，确保其不会演变为人工智能系统（例如，通过增加不同程度的自主性或推理能力）。
          更多详情，请参阅《人工智能法案》第 3(1) 条（人工智能系统的定义）及第 3(63) 条（通用人工智能模型的定义）。

      # ------------------------------------------------------------------------
      # 优先级 2：禁止事项（法规禁止该活动）
      # ------------------------------------------------------------------------
      - condition: "Unacceptable_risk == True"
        value: |
          根据《人工智能法案》第 5 条，此人工智能做法被严格禁止。被禁做法包括操纵技术、利用弱点、社会评分、非针对性的面部抓取以及在工作场所/学校进行情绪识别。所有运营商（包括提供者、部署者、分销商、进口商等）均不得将此系统投放市场。
          更多详情，请参阅《人工智能法案》第 5 条（禁止的做法）。

      # ------------------------------------------------------------------------
      # 优先级 3：角色检查
      # ------------------------------------------------------------------------
      - condition: "Role == 'Undetermined'"
        value: |
          您的实体不符合受监管经济运营商（提供者、部署者、进口商、分销商或授权代表）的定义。请查阅《人工智能法案》第 25 条，确保您不是以自己的名义将人工智能投放市场的“产品制造商”，否则您将被重新归类为提供者。
          更多详情，请参阅《人工智能法案》第 3 条（定义）及第 25 条（人工智能价值链中的责任）。

      # ------------------------------------------------------------------------
      # 优先级 3：现实世界测试（扩展）
      # ------------------------------------------------------------------------
      - condition: "(Risk_level == 'High Risk with Additional Transparency Obligation (Real World Testing)') and (Role == 'provider')"
        value: |
          作为提供者，您必须向市场监督机构提交现实世界测试计划，在欧盟数据库中注册该测试，并获得受试者的知情同意。您还必须确保受影响人员能检测到该系统是人工智能。
          更多详情，请参阅第 13 条（使用说明）、第 49 条（注册详情）、第 50 条（透明度）、第 60 条（现实世界测试）、第 61 条（知情同意）、第 71 条（欧盟数据库）及第 73 条（严重事件报告）。

      - condition: "(Risk_level == 'High Risk with Additional Transparency Obligation (Real World Testing)') and (Role != 'provider')"
        value: |
          如果您是部署者、潜在部署者或合作伙伴，您必须与提供者签订协议明确角色。您必须确保受试者知晓他们正在与人工智能互动。如果您是授权代表，您可能需要协助注册。
          更多详情，请参阅《人工智能法案》第 13 条（使用说明）、第 60 条（现实世界测试）、第 61 条（知情同意）、第 50 条（透明度）等。

      - condition: "(Risk_level == 'High Risk (Real World Testing)') and (Role == 'provider')"
        value: |
          作为提供者，您必须制定并向市场监督机构提交测试计划。您必须在欧盟数据库中注册该测试，并确保获得所有受试者的知情同意。
          更多详情，请参阅《人工智能法案》第 13 条（使用说明）、第 49 条（注册详情）、第 60 条（现实世界测试）、第 61 条（知情同意）及第 71 条（欧盟数据库）。

      - condition: "(Risk_level == 'High Risk (Real World Testing)') and (Role != 'provider')"
        value: |
          如果您是部署者、潜在部署者或合作伙伴，您必须严格遵守与提供者签订的协议，并确保遵循使用说明。您必须保持监督以保护受试者的安全。
          更多详情，请参阅第 13 条（使用说明）、第 26 条（部署者的义务）、第 60 条（现实世界测试）及第 61 条（知情同意）。

      # ------------------------------------------------------------------------
      # 优先级 4：通用人工智能 (GPAI)
      # ------------------------------------------------------------------------
      - condition: "(Risk_level == 'Systemic Risk GPAI' and Open_source == False) and (Role == 'provider')"
        value: |
          作为具有系统性风险模型的提供者，您必须通知委员会并遵守第 53 条的所有义务：维护技术文档、向下游提供者提供信息、实施版权政策并发布训练内容摘要。
          此外，您必须履行第 55 条的义务：进行对抗性测试、评估并减轻系统性风险、向人工智能办公室报告严重事件，并确保充分的网络安全。
          更多详情，请参阅《人工智能法案》第 52 条（通知）、第 53 条（一般义务）及第 55 条（系统性风险义务）。

      - condition: "(Risk_level == 'Systemic Risk GPAI' and Open_source == False) and (Role != 'provider')"
        value: |
          授权代表（非欧盟提供者必须指派）必须核实技术文档并将其保存 10 年。
          下游提供者有权就侵权行为提出投诉。如果下游提供者将此模型集成到高风险人工智能系统中，他们可能需要根据第 25 条承担提供者的义务。
          更多详情，请参阅《人工智能法案》第 54 条（授权代表）及第 89 条（补救措施）。

      - condition: "(Risk_level == 'Systemic Risk GPAI' and Open_source == True) and (Role == 'provider')"
        value: |
          由于该模型存在系统性风险，标准的开源文档豁免不适用。
          您必须遵守所有提供者义务：编写技术文档、向下游提供者提供信息、确立版权合规性并发布训练摘要。
          您还必须进行对抗性测试、减轻系统性风险并报告事件。
          更多详情，请参阅《人工智能法案》第 53(2) 条（例外覆盖）及第 55 条（系统性风险义务）。

      - condition: "(Risk_level == 'Systemic Risk GPAI' and Open_source == True) and (Role != 'provider')"
        value: |
          由于模型存在系统性风险（覆盖了授权代表的开源例外），非欧盟提供者必须指派授权代表。他们必须核实合规性并将文档保存 10 年。
          下游提供者必须从提供者处获得完整文档，并通常将此视为受监管的模型。
          更多详情，请参阅《人工智能法案》第 54 条（授权代表）。

      - condition: "(Risk_level == 'Standard GPAI') and (Role == 'provider')"
        value: |
          作为提供者，您必须编写并更新供人工智能办公室和国家主管部门审查的技术文档。您还必须编写、更新并向打算集成该模型的下游提供者提供信息和文档。此外，您必须实施遵守欧盟版权法的政策，并公开发布用于训练模型内容的详细摘要。您必须按要求与委员会和国家主管部门合作。如果您位于第三国，必须通过书面授权在欧盟指派一名授权代表。
          更多详情，请参阅《人工智能法案》第 53 条（GPAI 提供者的义务）及第 54 条（授权代表）。

      - condition: "(Risk_level == 'Standard GPAI') and (Role != 'provider')"
        value: |
          授权代表必须核实技术文档已编写且义务已履行，将文档副本供人工智能办公室和国家主管部门查阅并保存 10 年，根据合理要求向人工智能办公室提供必要信息，并配合当局采取的任何行动。如果他们认为提供者违反了义务，必须终止授权并立即通知人工智能办公室。下游提供者有权就违反本法规的行为提出投诉。
          更多详情，请参阅《人工智能法案》第 54 条（授权代表）及第 89 条（补救措施）。

      - condition: "(Risk_level == 'Standard GPAI (Open Source)') and (Role == 'provider')"
        value: |
          如果您的模型是根据允许访问、使用、修改和分发的免费开源许可证发布的，并且其参数、架构和使用信息已公开发布，则您免除向主管部门和下游提供者提供技术文档的义务。但是，如果模型存在系统性风险，此豁免不适用。您仍必须实施遵守欧盟版权法的政策，发布训练内容摘要，并与委员会和国家主管部门合作。
          更多详情，请参阅《人工智能法案》第 53(2) 条（开源）及第 53(1)(c)-(d) 条（版权和摘要）。

      - condition: "(Risk_level == 'Standard GPAI (Open Source)') and (Role != 'provider')"
        value: |
          除非模型存在系统性风险，否则指派授权代表的义务不适用于第 53(2) 条定义的开源模型提供者。下游提供者应核实提供者已实施遵守欧盟版权法的政策，并已发布训练内容摘要。
          更多详情，请参阅《人工智能法案》第 54(6) 条（授权代表例外覆盖）。

      # ------------------------------------------------------------------------
      # 优先级 5：高风险与透明度
      # ------------------------------------------------------------------------
      - condition: "(Risk_level == 'High Risk with Additional Transparency Obligations') and (Role == 'provider')"
        value: |
          作为提供者，您必须履行所有高风险义务（合格评定、质量管理体系、注册）。此外，您在设计系统时必须告知自然人他们正在与人工智能互动，除非根据具体情况显而易见。如果系统生成合成音频、图像、视频或文本，您必须以机器可读格式将输出标记为人工生成或操纵的内容。
          更多详情，请参阅《人工智能法案》第 16 条（提供者义务）及第 50 条（透明度）。

      - condition: "(Risk_level == 'High Risk with Additional Transparency Obligations') and (Role == 'deployer')"
        value: |
          作为部署者，您必须监控系统并确保人工监督。您有责任告知接触情绪识别或生物特征分类系统的自然人系统的运行情况。如果您部署生成深度伪造（Deep Fakes）的系统，必须披露内容是人工生成或操纵的。如果您发布人工智能生成的文本以向公众通报公共利益事项，必须披露其为人工生成。在工作场所投入使用高风险系统前，您还必须告知工人及其代表。
          更多详情，请参阅《人工智能法案》第 26 条（部署者义务）及第 50 条（透明度）。

      - condition: "(Risk_level == 'High Risk with Additional Transparency Obligations') and ((Role != 'provider') and (Role != 'deployer'))"
        value: |
          进口商和分销商在提供系统之前，必须核实系统带有必要的标记（包括 CE 标志）和说明。他们必须确保存储或运输条件不影响合规性。授权代表必须核实符合性声明和技术文档。以自己名义投放人工智能的产品制造商需承担提供者的义务。
          更多详情，请参阅《人工智能法案》第 23 条（进口商）、第 24 条（分销商）、第 22 条（授权代表）及第 25 条（制造商）。

      - condition: "(Risk_level == 'High Risk') and (Role == 'provider')"
        value: |
          作为提供者，您必须建立风险管理系统，确保数据治理，并编写技术文档。您必须拥有质量管理体系，保存自动生成的日志，并进行合格评定。您必须在欧盟数据库中注册系统并贴上 CE 标志。您还必须建立上市后监控系统，并向市场监督机构报告严重事件。
          更多详情，请参阅《人工智能法案》第 9 条（风险管理）、第 16 条（提供者义务）、第 43 条（合格性）及第 49 条（注册）。

      - condition: "(Risk_level == 'High Risk') and (Role == 'deployer')"
        value: |
          作为部署者，您必须按照说明使用系统，指派人工监督，并确保输入数据相关且具有代表性。您必须监控系统的运行，并向提供者通报任何风险或严重事件。如果系统在您的控制之下，您必须保存自动生成的日志至少六个月。公共当局必须在欧盟数据库中注册其使用情况。某些部署者必须进行基本权利影响评估（FRIA）。
          更多详情，请参阅《人工智能法案》第 26 条（部署者义务）、第 27 条（FRIA）及第 49 条（注册）。

      - condition: "(Risk_level == 'High Risk') and ((Role != 'provider') and (Role != 'deployer'))"
        value: |
          进口商必须确保提供者已完成合格评定，编写了技术文档并指派了代表。进口商必须保存证书和说明副本 10 年。分销商必须核实 CE 标志、符合性声明和说明。两者都必须确保存储和运输不影响合规性。授权代表必须将文档供主管部门查阅，如果提供者违反义务，必须终止其授权。
          更多详情，请参阅《人工智能法案》第 23 条（进口商）、第 24 条（分销商）及第 22 条（授权代表）。

      - condition: "(Risk_level == 'Transparency Obligation Only') and (Role == 'provider')"
        value: |
          作为提供者，您必须确保遵守第 50 条：
          1. 设计旨在与自然人直接互动的系统时，告知他们正在与人工智能系统互动，除非根据具体情况显而易见（例外：用于犯罪侦查/调查的授权执法使用，除非可供公众报告）。
          2. 确保生成合成音频、图像、视频或文本输出的系统以机器可读格式进行标记，并可检测为人工生成。
          3. 确保这些标记解决方案有效、可互操作、稳健且可靠（标记例外：不实质性改变输入数据/语义的标准编辑辅助功能，或授权执法使用）。
          更多详情，请参阅《人工智能法案》第 50 条（透明度义务）。

      - condition: "(Risk_level == 'Transparency Obligation Only') and (Role == 'deployer')"
        value: |
          作为部署者，您必须在以下场景中披露人工智能的使用：
          1. 情绪识别和生物特征分类：您必须告知接触此类系统的自然人系统的运行情况（例外：授权执法使用）。
          2. 深度伪造（Deep Fakes）：您必须披露为类似现有人员/事件而生成或操纵的图像、音频或视频内容是人工生成的。
             - 艺术例外：对于明显的艺术、创意、讽刺或虚构作品，披露仅限于适当的方式，且不影响欣赏。
          3. 公共利益文本：您必须披露为向公众通报公共利益事项而发布的文本是人工生成的。
             - 编辑例外：如果内容经过人工审查/编辑控制且有人承担编辑责任，则无需披露。
          4. 一般要求：信息必须清晰、可区分、符合无障碍要求，并最迟在首次互动时提供。
          更多详情，请参阅《人工智能法案》第 50 条（透明度义务）。

      - condition: "(Risk_level == 'Transparency Obligation Only') and (Role != 'provider' and Role != 'deployer')"
        value: |
          作为分销商、进口商或其他第三方，您需遵守以下规定：
          1. 视同提供者身份：如果您以自己的名义或商标将系统投放市场、进行实质性修改或修改人工智能系统的预期用途，您将被视为“提供者”并受所有提供者义务（包括第 50 条透明度）的约束。
          2. 核实：进口商必须核实提供者已编写技术文档且系统附带使用说明。分销商必须核实系统附带使用说明且提供者和进口商已履行其义务。
          更多详情，请参阅《人工智能法案》第 25 条（人工智能价值链中的责任）、第 23 条（进口商）、第 24 条（分销商）及第 22 条（授权代表）。

      # ------------------------------------------------------------------------
      # 优先级 6：极低风险
      # ------------------------------------------------------------------------
      - condition: "Risk_level == 'Minimal Risk'"
        value: |
          此系统属于极低风险类别。《人工智能法案》未对此施加强制性义务。但是，鼓励提供者和部署者自愿遵守行为准则。
          更多详情，请参阅《人工智能法案》第 95 条（行为准则）。
      
      - condition: "Risk_level == 'Minimal Risk (Open Source)'"
        value: |
          此系统属于极低风险类别，并根据免费开源许可证发布。
          根据《人工智能法案》第 2(12) 条，除非涉及高风险、被禁止或受透明度义务约束，否则该法规不适用于根据免费开源许可证发布的人工智能系统。因此，该系统明确免除法规的强制性义务。
          但是，仍鼓励遵守自愿行为准则。
          更多详情，请参阅《人工智能法案》第 2 条（范围）及第 95 条（行为准则）。

router:
  - condition: "True"
    action: "terminate"
    message: "Generate the report"
start: q1
questions:
  - id: q1
    kind: single
    title: "Is your product developed and put into service exclusively for scientific research and development?"
    description: "Ref: Art 2(6). This Regulation shall not apply to AI systems or AI models, including their output, specifically developed and put into service for the sole purpose of scientific research and development."
    options:
      - label: "Yes"
        value: "yes"
        next: { type: "result", id: "excluded_scientific_rd" }
      - label: "No"
        value: "no"
        next: { type: "question", id: "q2" }

  - id: q2
    kind: single
    title: "Is your product currently in a pre-market research, testing, or development phase?"
    description: "Ref: Art 2(8). This Regulation does not apply to any research, testing or development activity regarding AI systems or AI models prior to their being placed on the market or put into service."
    options:
      - label: "Yes"
        value: "yes"
        next: { type: "question", id: "q2a" }
      - label: "No"
        value: "no"
        next: { type: "question", id: "q3" }

  - id: q2a
    kind: single
    title: "Is any testing conducted in 'real-world conditions' outside of a laboratory or simulated environment?"
    description: "Ref: Art 2(8), Art 57(1). Testing in real world conditions shall not be covered by that exclusion. Art 60 outlines requirements for testing in real world conditions."
    bullets:
      - "Select YES if testing occurs outside a lab/simulation (regulated activity)."
      - "Select NO if testing is confined to a lab/simulation (exempt activity)."
    options:
      - label: "Yes"
        value: "yes"
        next: { type: "question", id: "q4" }
      - label: "No"
        value: "no"
        next: { type: "result", id: "excluded_pre_market_rd" }

  - id: q3
    kind: single
    title: "Does your product fall under a specific exclusion for military, defense, or purely personal use?"
    description: "Ref: Art 2(3), Art 2(10). This Regulation does not apply to AI systems ... exclusively for military, defence or national security purposes [or] to obligations of deployers who are natural persons using AI systems in the course of a purely personal non-professional activity."
    options:
      - label: "Yes, exclusively for military, defense, or national security purposes."
        value: "excl_military_defence"
        next: { type: "result", id: "excluded_specific_exclusion" }
      - label: "Yes, used by a natural person for purely personal, non-professional activity."
        value: "excl_personal_non_professional"
        next: { type: "result", id: "excluded_specific_exclusion" }
      - label: "No"
        value: "none"
        next: { type: "question", id: "q4" }

  - id: q4
    kind: single
    title: "How is your product best classified: General-Purpose AI Model, AI System, or Neither?"
    description: "Ref: Art 3(1), Art 3(63). 'AI system' means a machine-based system ... that infers, from the input it receives, how to generate outputs. 'General-purpose AI model' means an AI model ... capable of competently performing a wide range of distinct tasks."
    bullets:
      - "General-Purpose AI Model: You provide the core model (e.g., LLM, weights, API) capable of distinct tasks."
      - "AI System: You provide a software system designed to operate with autonomy and infer outputs."
      - "None of the above: Traditional software or does not meet the definitions above."
    options:
      - label: "General-Purpose AI Model"
        value: "option_a_gp_ai_model"
        next: { type: "question", id: "q5" }
      - label: "AI System"
        value: "option_b_ai_system"
        next: { type: "question", id: "q7" }
      - label: "None of the above"
        value: "option_c_not_ai"
        next: { type: "result", id: "excluded_not_ai" }

  - id: q5
    kind: single
    title: "Does your General-Purpose AI Model meet the criteria for 'Systemic Risk'?"
    description: "Ref: Art 51. A general-purpose AI model shall be classified as ... with systemic risk if ... (a) it has high impact capabilities ... presumed when the cumulative amount of computation ... is greater than 10^25 floating point operations."
    bullets:
      - "Cumulative training computation > 10^25 FLOPS."
      - "Designated by the Commission as having equivalent high-impact capabilities."
    options:
      - label: "Yes"
        value: "yes"
        next: { type: "result", id: "gpai_systemic_risk" }
      - label: "No"
        value: "no"
        next: { type: "question", id: "q6" }

  - id: q6
    kind: single
    title: "Is the model released under a free and open-source licence with publicly available parameters?"
    description: "Ref: Art 53(2). The obligations ... shall not apply to providers of AI models that are released under a free and open-source licence ... and whose parameters, including the weights, the information on the model architecture, and the information on model usage, are made publicly available."
    options:
      - label: "Yes"
        value: "yes"
        next: { type: "result", id: "gpai_open_source" }
      - label: "No"
        value: "no"
        next: { type: "result", id: "gpai_standard" }

  - id: q7
    kind: multi
    title: "Does your system utilize any of the following 'Prohibited Practices'?"
    description: "Ref: Art 5. The following AI practices shall be prohibited: [manipulative techniques, exploiting vulnerabilities, social scoring, crime prediction based on profiling, untargeted facial scraping, emotion recognition in work/school, biometric categorization of sensitive traits, real-time remote biometric ID in public]."
    options:
      - label: "Subliminal, manipulative, or deceptive techniques causing significant harm."
        value: "pp_manipulative_harm"
      - label: "Exploiting vulnerabilities (age, disability, social situation) causing significant harm."
        value: "pp_exploit_vulnerabilities"
      - label: "Social scoring leading to unjustified detrimental treatment."
        value: "pp_social_scoring"
      - label: "Risk assessment of criminal offenses based solely on profiling or personality traits."
        value: "pp_crime_risk_profiling_only"
      - label: "Creating/expanding facial recognition databases via untargeted scraping."
        value: "pp_untargeted_scraping_faces"
      - label: "Emotion recognition in workplaces or educational institutions (except for medical/safety)."
        value: "pp_emotion_work_school"
      - label: "Biometric categorization inferring sensitive traits (race, politics, religion, etc.)."
        value: "pp_sensitive_biometric_categorization"
      - label: "Real-time remote biometric identification in public spaces for law enforcement."
        value: "pp_real_time_remote_biometric_id"
      - label: "None of the above"
        value: "none"
        exclusive: true
    next_any: { type: "result", id: "prohibited_ai_practice" }
    next_none: { type: "question", id: "q8" }

  - id: q8
    kind: single
    title: "Is the system a safety component of a product listed in Annex I (or the product itself) requiring third-party conformity assessment?"
    description: "Ref: Art 6(1). [High-risk if]: (a) the AI system is intended to be used as a safety component of a product, or ... is itself a product, covered by the Union harmonisation legislation listed in Annex I; AND (b) the product ... is required to undergo a third-party conformity assessment."
    bullets:
      - "Applicable to sectors like Machinery, Toys, Medical Devices, Lifts, Vehicles, Civil Aviation, etc."
    options:
      - label: "Yes"
        value: "yes"
        next: { type: "question", id: "q10_high_risk_annex1" }
      - label: "No"
        value: "no"
        next: { type: "question", id: "q9" }

  - id: q9
    kind: multi
    title: "Is the system intended to be used in any of the following 'High-Risk' areas listed in Annex III?"
    description: "Ref: Annex III. High-risk AI systems pursuant to Article 6(2) are the AI systems listed in any of the following areas: [Biometrics, Critical Infrastructure, Education, Employment, Essential Services, Law Enforcement, Migration/Border Control, Justice/Democracy]."
    options:
      - label: "Biometrics: Remote identification (non-real-time), categorization (non-sensitive), emotion recognition."
        value: "a3_biometrics"
      - label: "Critical Infrastructure: Safety components in road traffic, water, gas, heating, electricity."
        value: "a3_critical_infrastructure"
      - label: "Education/Training: Access assignment, evaluation of outcomes, proctoring."
        value: "a3_education"
      - label: "Employment: Recruitment, termination, task allocation, performance monitoring."
        value: "a3_employment"
      - label: "Essential Services: Credit scoring, insurance risk, emergency dispatch, benefits eligibility."
        value: "a3_essential_services"
      - label: "Law Enforcement: Polygraphs, evidence reliability, profiling, risk assessment."
        value: "a3_law_enforcement"
      - label: "Migration/Border Control: Polygraphs, application examination, security risk assessment."
        value: "a3_migration_border"
      - label: "Justice/Democracy: Judicial interpretation assistance, influencing elections."
        value: "a3_justice_democracy"
      - label: "None of the above"
        value: "none"
        exclusive: true
    next_any: { type: "question", id: "q9a_profiling" }
    next_none: { type: "question", id: "q10_minimal_risk" }

  - id: q9a_profiling
    kind: single
    title: "Does the system perform profiling of natural persons?"
    description: "Ref: Art 6(3). An AI system referred to in Annex III shall always be considered to be high-risk where the AI system performs profiling of natural persons."
    options:
      - label: "Yes"
        value: "yes"
        next: { type: "question", id: "q10_high_risk_annex3" }
      - label: "No"
        value: "no"
        next: { type: "question", id: "q9a_derogation" }

  - id: q9a_derogation
    kind: multi
    title: "Does the system meet any of the following conditions to be exempt from High-Risk classification (Derogation)?"
    description: "Ref: Art 6(3). [Not] high-risk where it does not pose a significant risk of harm ... fulfilled where: (a) intended to perform a narrow procedural task; (b) intended to improve the result of a previously completed human activity; (c) intended to detect decision-making patterns ... not meant to replace ... human assessment; (d) intended to perform a preparatory task."
    options:
      - label: "Performs a narrow procedural task."
        value: "derog_narrow_procedural"
      - label: "Improves the result of a previously completed human activity."
        value: "derog_improves_human_result"
      - label: "Detects decision-making patterns without replacing human assessment."
        value: "derog_detects_patterns_no_replace"
      - label: "Performs a preparatory task for an assessment."
        value: "derog_preparatory_task"
      - label: "None of the above"
        value: "none"
        exclusive: true
    next_any: { type: "question", id: "q10_derogation" }
    next_none: { type: "question", id: "q10_high_risk_annex3" }

  - id: q10_high_risk_annex1
    kind: multi
    title: "Does the system trigger any of the following 'Transparency Obligations'?"
    description: "Ref: Art 50. Providers shall ensure that AI systems intended to interact directly with natural persons ... are informed ... [and] Providers of AI systems ... generating synthetic audio, image, video or text content, shall ensure that the outputs ... are marked ... [and] Deployers of an emotion recognition system or a biometric categorisation system shall inform the natural persons ... [and] Deployers ... [of] deep fake, shall disclose that the content has been artificially generated."
    options:
      - label: "Interacts directly with natural persons (e.g., chatbots)."
        value: "tr_interacts_with_people"
      - label: "Generates synthetic audio, image, video, or text content."
        value: "tr_generates_synthetic_content"
      - label: "Performs emotion recognition or biometric categorization."
        value: "tr_emotion_or_biometric_categorization"
      - label: "Generates deepfakes or manipulated content."
        value: "tr_deepfakes"
      - label: "None of the above"
        value: "none"
        exclusive: true
    next_any: { type: "result", id: "high_risk_annex1_transparency" }
    next_none: { type: "result", id: "high_risk_annex1" }

  - id: q10_high_risk_annex3
    kind: multi
    title: "Does the system trigger any of the following 'Transparency Obligations'?"
    description: "Ref: Art 50. Providers shall ensure that AI systems intended to interact directly with natural persons ... are informed ... [and] Providers of AI systems ... generating synthetic audio, image, video or text content, shall ensure that the outputs ... are marked ... [and] Deployers of an emotion recognition system or a biometric categorisation system shall inform the natural persons ... [and] Deployers ... [of] deep fake, shall disclose that the content has been artificially generated."
    options:
      - label: "Interacts directly with natural persons (e.g., chatbots)."
        value: "tr_interacts_with_people"
      - label: "Generates synthetic audio, image, video, or text content."
        value: "tr_generates_synthetic_content"
      - label: "Performs emotion recognition or biometric categorization."
        value: "tr_emotion_or_biometric_categorization"
      - label: "Generates deepfakes or manipulated content."
        value: "tr_deepfakes"
      - label: "None of the above"
        value: "none"
        exclusive: true
    next_any: { type: "result", id: "high_risk_annex3_transparency" }
    next_none: { type: "result", id: "high_risk_annex3" }

  - id: q10_derogation
    kind: multi
    title: "Does the system trigger any of the following 'Transparency Obligations'?"
    description: "Ref: Art 50. Providers shall ensure that AI systems intended to interact directly with natural persons ... are informed ... [and] Providers of AI systems ... generating synthetic audio, image, video or text content, shall ensure that the outputs ... are marked ... [and] Deployers of an emotion recognition system or a biometric categorisation system shall inform the natural persons ... [and] Deployers ... [of] deep fake, shall disclose that the content has been artificially generated."
    options:
      - label: "Interacts directly with natural persons (e.g., chatbots)."
        value: "tr_interacts_with_people"
      - label: "Generates synthetic audio, image, video, or text content."
        value: "tr_generates_synthetic_content"
      - label: "Performs emotion recognition or biometric categorization."
        value: "tr_emotion_or_biometric_categorization"
      - label: "Generates deepfakes or manipulated content."
        value: "tr_deepfakes"
      - label: "None of the above"
        value: "none"
        exclusive: true
    next_any: { type: "result", id: "non_high_risk_derogation_transparency" }
    next_none: { type: "question", id: "q11_open_source_derogation" }

  - id: q10_minimal_risk
    kind: multi
    title: "Does the system trigger any of the following 'Transparency Obligations'?"
    description: "Ref: Art 50. Providers shall ensure that AI systems intended to interact directly with natural persons ... are informed ... [and] Providers of AI systems ... generating synthetic audio, image, video or text content, shall ensure that the outputs ... are marked ... [and] Deployers of an emotion recognition system or a biometric categorisation system shall inform the natural persons ... [and] Deployers ... [of] deep fake, shall disclose that the content has been artificially generated."
    options:
      - label: "Interacts directly with natural persons (e.g., chatbots)."
        value: "tr_interacts_with_people"
      - label: "Generates synthetic audio, image, video, or text content."
        value: "tr_generates_synthetic_content"
      - label: "Performs emotion recognition or biometric categorization."
        value: "tr_emotion_or_biometric_categorization"
      - label: "Generates deepfakes or manipulated content."
        value: "tr_deepfakes"
      - label: "None of the above"
        value: "none"
        exclusive: true
    next_any: { type: "result", id: "transparency_obligations_only" }
    next_none: { type: "question", id: "q11_open_source_minimal" }

  - id: q11_open_source_derogation
    kind: single
    title: "Is the system released under a free and open-source licence?"
    description: "Ref: Art 2(12). This Regulation does not apply to AI systems released under free and open-source licences, unless they are placed on the market or put into service as high-risk AI systems or as an AI system that falls under Article 5 [Prohibited] or 50 [Transparency]."
    options:
      - label: "Yes"
        value: "yes"
        next: { type: "result", id: "excluded_open_source_ai_system_derogation" }
      - label: "No"
        value: "no"
        next: { type: "result", id: "general_ai_system_minimal_risk_derogation" }

  - id: q11_open_source_minimal
    kind: single
    title: "Is the system released under a free and open-source licence?"
    description: "Ref: Art 2(12). This Regulation does not apply to AI systems released under free and open-source licences, unless they are placed on the market or put into service as high-risk AI systems or as an AI system that falls under Article 5 [Prohibited] or 50 [Transparency]."
    options:
      - label: "Yes"
        value: "yes"
        next: { type: "result", id: "excluded_open_source_ai_system" }
      - label: "No"
        value: "no"
        next: { type: "result", id: "general_ai_system_minimal_risk" }

results:
  - id: "excluded_scientific_rd"
    title: "EXCLUDED: Scientific R&D"
    description: "Ref: Art 2(6). The Regulation does not apply as the product is exclusively for scientific research and development."

  - id: "excluded_pre_market_rd"
    title: "EXCLUDED: Pre-market R&D"
    description: "Ref: Art 2(8). The Regulation does not apply to pre-market research, testing, or development activities (excluding real-world testing)."

  - id: "excluded_specific_exclusion"
    title: "EXCLUDED: Specific Exemption"
    description: "Ref: Art 2(3), Art 2(10). The Regulation does not apply due to military/defense exemption or purely personal non-professional use."

  - id: "excluded_not_ai"
    title: "EXCLUDED: Not an AI System/Model"
    description: "Ref: Art 3(1), Art 3(63). The product does not meet the legal definition of an AI System or General-Purpose AI Model."

  - id: "gpai_systemic_risk"
    title: "REGULATED: General-Purpose AI Model with Systemic Risk"
    description: "Ref: Art 55. The model is classified as having systemic risk. Obligations include model evaluation, adversarial testing ('red-teaming'), systemic risk assessment, and incident reporting."

  - id: "gpai_open_source"
    title: "REGULATED: General-Purpose AI Model (Open Source)"
    description: "Ref: Art 53(2). Exempt from most documentation rules. You MUST still comply with copyright policies (Art 53(1)(c)) and publish a detailed summary of training content (Art 53(1)(d))."

  - id: "gpai_standard"
    title: "REGULATED: General-Purpose AI Model"
    description: "Ref: Art 53. You must maintain technical documentation, provide information to downstream providers, comply with copyright policies, and publish a training content summary."

  - id: "prohibited_ai_practice"
    title: "PROHIBITED: Banned AI Practice"
    description: "Ref: Art 5. The system utilizes practices deemed an unacceptable risk (e.g., manipulation, social scoring, certain biometrics) and is prohibited from being placed on the Union market."

  - id: "high_risk_annex1"
    title: "HIGH-RISK: Regulated Product Safety Component (Annex I)"
    description: "Ref: Art 6(1). The system is High-Risk. You must comply with Chapter III obligations, including Risk Management, Data Governance, Technical Documentation, Record Keeping, Transparency, Human Oversight, Accuracy/Cybersecurity, and Conformity Assessment."

  - id: "high_risk_annex1_transparency"
    title: "HIGH-RISK (Annex I) + Transparency Obligations"
    description: "Ref: Art 6(1) & Art 50. The system is High-Risk. You must comply with all Chapter III obligations (Risk Mgmt, Data Gov, etc.) AND Article 50 Transparency rules (e.g., disclosing AI interaction or synthetic content)."

  - id: "high_risk_annex3"
    title: "HIGH-RISK: Critical Area (Annex III)"
    description: "Ref: Art 6(2). The system is High-Risk due to its use in a critical area. You must comply with Chapter III obligations, including Risk Management, Data Governance, Technical Documentation, Record Keeping, Transparency, Human Oversight, Accuracy/Cybersecurity, and Conformity Assessment."

  - id: "high_risk_annex3_transparency"
    title: "HIGH-RISK (Annex III) + Transparency Obligations"
    description: "Ref: Art 6(2) & Art 50. The system is High-Risk. You must comply with all Chapter III obligations AND Article 50 Transparency rules (e.g., disclosing AI interaction or synthetic content)."

  - id: "non_high_risk_derogation_transparency"
    title: "REGULATED: Transparency Obligations (Derogation Applied)"
    description: "Ref: Art 6(3) & Art 50. You have successfully assessed the system as Non-High-Risk (Derogation). You MUST register this assessment. Additionally, you MUST comply with Article 50 Transparency obligations."

  - id: "excluded_open_source_ai_system"
    title: "EXCLUDED: Open Source AI System"
    description: "Ref: Art 2(12). The Regulation does not apply as the system is open-source and does not fall under High-Risk, Prohibited, or Transparency classifications."

  - id: "excluded_open_source_ai_system_derogation"
    title: "EXCLUDED: Open Source AI System (Derogation Applied)"
    description: "Ref: Art 2(12). The Regulation does not apply. You have successfully assessed the system as Non-High-Risk (Derogation), and as it is Open-Source, it is excluded from further regulation."

  - id: "general_ai_system_minimal_risk"
    title: "MINIMAL RISK: General AI System"
    description: "Ref: Art 69. No mandatory obligations apply under this Regulation. Adherence to voluntary codes of conduct is encouraged."

  - id: "general_ai_system_minimal_risk_derogation"
    title: "MINIMAL RISK: General AI System (Derogation Applied)"
    description: "Ref: Art 6(3). You have successfully assessed the system as Non-High-Risk. You MUST register this derogation assessment. Beyond that, no mandatory obligations apply."

  - id: "transparency_obligations_only"
    title: "REGULATED: Transparency Obligations Apply"
    description: "Ref: Art 50. The system is not High-Risk, but Article 50 applies. You must ensure transparency (e.g., informing users they are interacting with AI, labeling deepfakes/synthetic content)."